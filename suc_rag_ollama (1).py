# -*- coding: utf-8 -*-
"""suc_rag_ollama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8GOnFGOIr5Y7xdnfC-Pd-uqr0yPn7yx
"""









!git clone https://huggingface.co/spaces/Mr-TD/Ollama-RAG

!curl -fsSL https://ollama.com/install.sh | sh

curl -fsSL https://ollama.com/install.sh | sh
nohup ollama serve &
ollama pull llama3:8b
ollama list

!nohup ollama serve &

!ollama pull llama3.1

!ollama list

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Ollama-RAG

!pip install -r requirements.txt

!pip install pyngrok

XXXXX
XXXXX

from pyngrok import ngrok
import threading
import time

ngrok_token = "XXXXX"
ngrok.set_auth_token(ngrok_token)

# Start ngrok in a separate thread to avoid blocking
def start_ngrok():
    public_url = ngrok.connect(3000).public_url
    print(f"ðŸš€ Ngrok Tunnel Open: {public_url}")

ngrok_thread = threading.Thread(target=start_ngrok)
ngrok_thread.start()

# Wait for ngrok to start (optional)
time.sleep(5)

# Execute your node.js script
!node hello-world.js

!which node
mv aa.js aa.mjs

!pip install pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Ollama-RAG

!nohup ollama serve &

from pyngrok import ngrok
import threading
import time

ngrok_token = "XXXXX"
ngrok.set_auth_token(ngrok_token)

# Start ngrok in a separate thread to avoid blocking
def start_ngrok():
    public_url = ngrok.connect(8501).public_url
    print(f"ðŸš€ Ngrok Tunnel Open: {public_url}")

ngrok_thread = threading.Thread(target=start_ngrok)
ngrok_thread.start()

# Wait for ngrok to start (optional)
time.sleep(5)

# Execute your node.js script
!streamlit run app.py

Demo_Document/Kia_EV6.pdf

!pip install faiss-cpu

/content/Ollama-RAG/requirements.txt

langchain==0.3.17
langchain_ollama==0.2.3
ollama==0.4.7
PyPDF2==3.0.1
streamlit==1.41.1
langchain-community==0.3.16